#!/bin/bash

# The configuration files from 
# HDUSER_HOME/mmu-conf directory. Everytime this
# start script is executed, hadoop-site.xml, masters, slaves files
# are re-generated by replacing the "localhost" with actual IP address of this 
# VM from the set of template files inside the HDUSER_HOME/mmu-conf directory.

# Note: If you want to change hadoop-site.xml 
# make changes to "HDUSER_HOME/mmu-conf/template/hadoop-site.xml" and 
# restart the hadoop daemons (restart-hadoop)

# get a list of ethernet network interfaces that are up
echo "============================================================" >&2
echo "(1) get a list of ethernet network interfaces that are up" >&2
echo "============================================================" >&2
echo "exec: eth_ifs=$(/bin/netstat -i | /bin/grep eth | /usr/bin/awk '{print $1}')" >&2
echo "exec: nifs=$(echo $eth_ifs | wc -w)" >&2
echo "exec: [ $nifs -ge 1 ] || exit 0;" >&2
echo "------------------------------------------------------------" >&2
eth_ifs=$(/bin/netstat -i | /bin/grep eth | /usr/bin/awk '{print $1}')
nifs=$(echo $eth_ifs | wc -w)
[ $nifs -ge 1 ] || exit 0;


echo -e "\n\n" >&2

# Select the first interface 
echo "============================================================" >&2
echo "(2) Select the first interface " >&2
echo "============================================================" >&2
echo "exec: eth1=$(echo \"$eth_ifs\" | /usr/bin/head -n 1)" >&2
echo "------------------------------------------------------------" >&2
eth1=$(echo "$eth_ifs" | /usr/bin/head -n 1)


echo -e "\n\n" >&2

# Get the IP address
echo "============================================================" >&2
echo "(3) Get the IP address" >&2
echo "============================================================" >&2
echo "exec: eth_ip=$(/sbin/ifconfig $eth1 | /bin/grep \"inet addr:\" | /usr/bin/awk '{print $2}' | /bin/sed \"s/addr://\")" >&2
echo "------------------------------------------------------------" >&2
eth_ip=$(/sbin/ifconfig $eth1 | /bin/grep "inet addr:" | /usr/bin/awk '{print $2}' | /bin/sed "s/addr://")


echo -e "\n\n" >&2

# Update HDUSER_HOME/mmu-conf/* files according to the 
# current IP address of the Virtual Machine
echo "============================================================" >&2
echo "(4) Update HDUSER_HOME/mmu-conf/* files according to the " >&2
echo "    current IP address of the Virtual Machine" >&2
echo "============================================================" >&2
echo "exec: ( cd $HDUSER_HOME/mmu-conf/template &&" >&2
echo "        for templ in ./*; do" >&2
echo "             sed \"s/localhost/$eth_ip/g\" < ./$templ > $HDUSER_HOME/mmu-conf/$templ" >&2
echo "        done" >&2
echo "       )" >&2
echo "       )" >&2
echo "------------------------------------------------------------" >&2
(
  cd $HDUSER_HOME/mmu-conf/template &&
  for templ in ./*; do
    sed "s/localhost/$eth_ip/g" < ./$templ > $HDUSER_HOME/mmu-conf/$templ
  done
)


echo -e "\n\n" >&2

# clean logs before starting daemons
# rm -rf /home/hduser/hadoop/logs/*

echo "============================================================" >&2
echo "Starting Hadoop..." >&2
echo "============================================================" >&2
echo "exec: export HADOOP_HOME=/usr/local/hadoop" >&2
echo "exec: export HDUSER_HOME=/home/hduser" >&2
echo "exec: export HADOOP_CONF_DIR=$HDUSER_HOME/mmu-conf" >&2
#echo "exec: ${HADOOP_HOME}"/sbin/start-all.sh" --config $HADOOP_CONF_DIR" >&2
echo "exec: ${HADOOP_HOME}"/sbin/start-dfs.sh" --config $HADOOP_CONF_DIR" >&2
echo "exec: ${HADOOP_HOME}"/sbin/start-yarn.sh" --config $HADOOP_CONF_DIR" >&2
echo "------------------------------------------------------------" >&2


export HADOOP_HOME=/usr/local/hadoop
export HDUSER_HOME=/home/hduser
export HADOOP_CONF_DIR=$HDUSER_HOME/mmu-conf

#${HADOOP_HOME}"/sbin/start-all.sh" --config $HADOOP_CONF_DIR
${HADOOP_HOME}"/sbin/start-dfs.sh" --config $HADOOP_CONF_DIR
${HADOOP_HOME}"/sbin/start-yarn.sh" --config $HADOOP_CONF_DIR
